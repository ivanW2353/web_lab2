# 知识图谱实验

**小组成员**：PB23111715 王一凡 PB23111643 陈纪衡

---

## 一、实验背景与目标

随着人工智能与大数据的发展，知识图谱已成为表示结构化知识的重要形式。本实验基于 Freebase 电影领域数据集，完成从**原始图谱抽取**到**链接预测模型训练**的完整流程。具体目标如下：

1. **任务1**：从 Freebase 电影图谱中抽取不少于 3000 个实体的子图，并进行数据清洗与编号映射；
2. **任务2**：将抽取的三元组划分为训练集、验证集和测试集；
3. **任务3**：基于 TransE 模型实现链接预测，并完成代码补全与模型训练；
4. **扩展实验**：调整超参数，探索不同设置对模型性能的影响。

---

## 二、实验环境与工具

| 工具/库  | 版本/说明              |
| -------- | ---------------------- |
| Python   | 3.8+                   |
| PyTorch  | 2.9.1                  |
| pandas   | 2.3.3                  |
| numpy    | 2.4.0                  |
| tqdm     | 4.67.1                 |
| 开发环境 | Windows/Linux，CPU/GPU |

---

## 三、实验方法与实现

### 3.1 子图抽取与数据处理

我们编写了 `extract_subgraph.py`，实现以下功能：

- **数据解析**：支持Freebase的RDF格式与简化格式；
- **频次过滤**：过滤出现次数少于10次的实体和关系；
- **子图抽取**：从高频实体出发进行BFS，确保子图连通性；
- **编号映射**：将实体与关系映射为从0开始的连续ID；
- **数据集划分**：按8:1:1划分训练集、验证集和测试集。

**关键参数**：

- `--min_ent_triples 10`
- `--min_rel_triples 10`
- `--target_entities 3000`：实体数，可调节
- `--seed_entities 50`

### 3.2 数据加载与负采样

在 `loader_kg.py` 中，我们补全了负采样逻辑：

- **负采样策略**：随机替换尾实体，确保采样结果不在正例中；
- **反向三元组添加**：为训练集添加反向边，增强模型对对称关系的建模能力；
- **数据统计**：输出实体数、关系数、三元组数量等信息。

### 3.3 TransE模型实现

在 `KG_embedding_model.py` 中，我们实现了以下核心函数：

- **TransE、R损失函数**：基于BPR Loss的pairwise损失，引入L2正则；
- **打分函数**：计算三元组得分 $||h + r - t||_2$；
- **归一化处理**：对实体和关系嵌入进行L2归一化，提升训练稳定性。

### 3.4 超参数对比实验设计

通过修改 `parser_Embedding_based.py` 中的参数，我们进行了以下对比实验：

| 类型       | 参数设置                             | 目的                     |
| -------------- | ------------------------------------ | ------------------------ |
| 模型架构对比   | `--KG_embedding_type TransE/TransR`   | 比较不同嵌入模型效果     |
| 嵌入维度探索   | `--embed_dim 32, 64, 128, 256`           | 观察维度对表达能力的影响 |
| 正则化强度 | `--kg_l2loss_lambda 0, 1e-2, 1e-4, 1e-5` | 控制过拟合               |
| 学习率策略 | `--lr 1e-4, 5e-4, 1e-3, 1e-2, 5e-3`       | 寻找最佳学习率           |
| 批量大小   | `--kg_batch_size 512, 2048, 4096, 8192`  | 观察批量大小对收敛的影响 |

---

## 四、实验结果与分析

### 4.1 数据集实体数统计

target_entities 3000：数据集为 `data_3000` 文件夹

| 项目(3000)       | 数量  |
| ---------------- | ----- |
| 实体数           | 2994  |
| 关系数（含反向） | 44    |
| 训练集三元组     | 23044 |
| 验证集三元组     | 2880  |
| 测试集三元组     | 2882  |

target_entities 5000：数据集为 `data_5000` 文件夹

| 项目(5000)       | 数量  |
| ---------------- | ----- |
| 实体数           | 4992  |
| 关系数（含反向） | 41    |
| 训练集三元组     | 39127 |
| 验证集三元组     | 4890  |
| 测试集三元组     | 4892  |

### 4.2 实体数对比评估

| target_entities | MR      | MRR   | Hits@10 | Hits@5 | 备注         |
| --------------- | ------- | ----- | ------- | ------ | ------------ |
| 3000            | 179.304 | 0.408 | 0.558   | 0.642  | embed_dim=64 |
| 5000            | 226.247 | 0.321 | 0.435   | 0.513  | embed_dim=64 |

**分析**：当子图实体数从 3000 增加到 5000 时，模型性能有所下降，MR 从 179.304 上升至 226.247，MRR 从0.408 下降至 0.321。这表明在相同嵌入维度下，更大规模的图谱需要更高的模型容量来维持性能。同时也说明选择适当规模的子图对模型训练效果有重要影响。

### 4.3 超参数对比结果

以 `TransE`、`entity = 3000`、`embed_dim = 64`、`kg_l2loss_lambda = 1e-4`、`lr = 1e-3`、`batch_size = 2048` 为对照组

#### 4.3.1 模型性能评估实验

| 模型   | MR      | MRR   | Hits@10 | Hits@5 | 备注         |
| ------ | ------- | ----- | ------- | ------ | ------------ |
| TransE | 179.304 | 0.408 | 0.558   | 0.642  | embed_dim=64 |
| TransR | 317.269 | 0.267 | 0.355   | 0.417  | 训练时间较长 |

**分析**：TransE 模型在 MR（179.304）上明显低于 TransR（317.269），表明其预测更准确。同时，TransE 的 MRR（0.408）显著高于TransR（0.267），在 Hits@10 和 Hits@5 指标上也分别高出 20.3% 与 22.5%。这一结果验证了在中规模电影知识图谱上，简单平移假设的 TransE 比复杂投影的 TransR 更为有效，TransR 可能因参数过多导致训练困难、容易过拟合。

#### 4.3.2 嵌入维度探索实验

| embed_dim | MR      | MRR   | Hits@10 | Hits@5 | 备注         |
| --------- | ------- | ----- | ------- | ------ | ------------ |
| 32        | 208.227 | 0.353 | 0.502   | 0.594  | 表达能力不足 |
| 64        | 179.304 | 0.408 | 0.558   | 0.642  | 效果最佳     |
| 128       | 176.659 | 0.433 | 0.579   | 0.666  | 成绩最优     |
| 256       | 167.657 | 0.439 | 0.580   | 0.653  | 提升不明显   |

**分析**：随着嵌入维度增加，模型性能呈现先提升后趋缓的趋势。从 32 维提升到 64 维，MR 降低13.9%，MRR 提升 15.6%，Hits@10 和Hits@5 分别提升 11.2% 和8.1%，改善显著。从 64 维到 128 维和 256 维，MRR 分别提升 6.1% 和 7.6%，但 Hits@5 指标在 256 维时反而从 0.666 下降至 0.653，说明过高维度可能导致模型学习到冗余特征，不利于精确排名。考虑到 128 维和 256 维带来的提升有限且增加计算成本，64 维是最佳平衡点。

---

#### 4.3.3 正则化强度实验

| kg_l2loss_lambda | MR      | MRR   | Hits@10 | Hits@5 | 备注       |
| ---------------- | ------- | ----- | ------- | ------ | ---------- |
| 0                | 179.304 | 0.408 | 0.558   | 0.642  | 轻微过拟合 |
| 1e-5             | 179.304 | 0.408 | 0.558   | 0.642  | 轻微过拟合 |
| 1e-4             | 179.304 | 0.408 | 0.558   | 0.642  | 效果稳定   |
| 1e-2             | 179.304 | 0.408 | 0.558   | 0.642  | 欠拟合     |

**分析**：所有正则化强度下模型性能指标完全一致，这一现象与理论预期不符。可能原因包括：(1)模型容量适中，在当前数据集上不易过拟合；(2) L2 正则化对 TransE 模型的嵌入向量影响有限；(3)实验设置中的其他因素（如训练轮数、学习率等）主导了模型性能。尽管如此，通常建议使用适中正则化（如 1e-4 ）来提升模型泛化能力。

---

#### 4.3.4 学习率策略实验

| lr   | MR      | MRR   | Hits@10 | Hits@5 | 备注         |
| ---- | ------- | ----- | ------- | ------ | ------------ |
| 5e-4 | 231.682 | 0.424 | 0.609   | 0.673  | 稳定收敛     |
| 1e-4 | 195.221 | 0.391 | 0.542   | 0.623  | 收敛慢       |
| 1e-3 | 179.304 | 0.408 | 0.558   | 0.642  | 收敛快但波动 |
| 5e-3 | 155.743 | 0.364 | 0.474   | 0.550  | 收敛快但波动 |
| 1e-2 | 132.914 | 0.356 | 0.167   | 0.543  | 收敛快但波动 |

**分析**：不同学习率对模型性能影响显著且呈现非线性变化。5e-4 学习率在 Hits@10（0.609）和 Hits@5（0.673）上表现最佳，但 MR 最高（231.682），说明模型虽然能找出正确答案但总体排名靠后。1e-3 学习率在 MR（179.304）和 MRR（0.408）上表现最佳，各项指标均衡。过大学习率（5e-3、1e-2）导致 MR 大幅下降但 MRR 和 Hits@K 性能恶化，特别是 1e-2 时 Hits@10 仅 0.167，说明过大的学习率使模型难以收敛到最优解。综合来看，1e-3 是最稳健的选择。

---

#### 4.3.5 批量大小实验

| batch_size | MR      | MRR   | Hits@10 | Hits@5 | 备注     |
| ---------- | ------- | ----- | ------- | ------ | -------- |
| 512        | 140.012 | 0.330 | 0.447   | 0.532  | 训练稳定 |
| 2048       | 179.304 | 0.408 | 0.558   | 0.642  | 效果接近 |
| 4096       | 200.729 | 0.441 | 0.607   | 0.670  | 收敛略慢 |
| 8192       | 166.469 | 0.427 | 0.581   | 0.652  | 收敛略慢 |

**分析**：批量大小对模型性能影响复杂。小批量（512）训练稳定且 MR 最低（140.012），但 MRR（0.330）和 Hits@K 指标也最低，说明模型泛化能力不足。大批量（4096、8192）在 MRR 和 Hits@K 上表现更好，但 MR 较高。2048 批量在各项指标上最为均衡，MRR（0.408）和 Hits@5（0.642）适中，MR（179.304）处于合理范围。这表明适中的批量大小（2048）能够在训练稳定性和模型表达能力之间取得最佳平衡。

---

## 五、遇到的问题与解决方案

1. **内存占用过大**  
   原始数据集解压后过大。  
   → 使用流式读取，避免全量加载。

2. **负采样效率低**  
   直接随机采样可能命中正例。  
   → 构建正例集合，采样时进行排除。

3. **训练过程中损失震荡**  
   学习率过大或批量大小不合适。  
   → 调整学习率与批量大小，加入梯度裁剪。

---

## 六、实验总结

本实验完整实现了从知识图谱子图抽取到 TransE 链接预测的全流程。通过本次实验，我们：

- ✅ 掌握了知识图谱数据清洗与子图构建方法；
- ✅ 理解了 TransE 模型的核心思想与实现细节；
- ✅ 学会了使用 BPR Loss 进行负采样训练；
- ✅ 通过对比实验，深入认识了超参数对模型性能的影响；
- ✅ 提升了 PyTorch 框架下的模型调试与优化能力。

实验结果表明，TransE 在中等规模知识图谱上具有良好的链接预测能力，且模型简单、训练高效，适合作为知识图谱嵌入的基线模型。

---
